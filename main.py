import os
import re
import uuid
import shutil
import logging
import requests
import telebot
import json
from flask import Flask, request, abort
from faster_whisper import WhisperModel
from datetime import datetime
from telebot.types import InlineKeyboardMarkup, InlineKeyboardButton

# NEW: Import imageio_ffmpeg and set the FFMPEG_PATH for pydub
try:
    import imageio_ffmpeg
    # Set the path for pydub to use the ffmpeg binary from imageio_ffmpeg
    # This environment variable tells pydub where to find ffmpeg
    os.environ["FFMPEG_PATH"] = imageio_ffmpeg.get_ffmpeg_exe()
    logging.info(f"Using ffmpeg from imageio_ffmpeg: {os.environ['FFMPEG_PATH']}")
except ImportError:
    logging.error("imageio-ffmpeg not installed. Please install it with 'pip install imageio-ffmpeg'.")
    logging.warning("pydub will try to find ffmpeg in your system's PATH.")
except Exception as e:
    logging.error(f"Error setting FFMPEG_PATH from imageio_ffmpeg: {e}")
    logging.warning("pydub will try to find ffmpeg in your system's PATH.")

from pydub import AudioSegment # Added: For audio manipulation
# from pydub.silence import split_on_silence # Potentially useful for smart chunking, but not strictly needed for fixed chunks


# Configure logger
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Bot token
TOKEN = "7770743573:AAHHnK_Ameb8GkqgvK3LQUp3l0dN3njecN4"

bot = telebot.TeleBot(TOKEN, threaded=True)
app = Flask(__name__)

# Admin ID
ADMIN_ID = 5978150981

# Download directory
DOWNLOAD_DIR = "downloads"
os.makedirs(DOWNLOAD_DIR, exist_ok=True)

# Whisper model for transcription
model = WhisperModel(model_size_or_path="tiny", device="cpu", compute_type="int8")

# User tracking file
users_file = 'users.json'
user_data = {}
if os.path.exists(users_file):
    with open(users_file, 'r') as f:
        try:
            user_data = json.load(f)
        except json.JSONDecodeError:
            user_data = {}

# User-specific language settings
user_language_settings_file = 'user_language_settings.json'
user_language_settings = {}
if os.path.exists(user_language_settings_file):
    with open(user_language_settings_file, 'r') as f:
        try:
            user_language_settings = json.load(f)
        except json.JSONDecodeError:
            user_language_settings = {}

def save_user_data():
    with open(users_file, 'w') as f:
        json.dump(user_data, f, indent=4)

def save_user_language_settings():
    with open(user_language_settings_file, 'w') as f:
        json.dump(user_language_settings, f, indent=4)

# In-memory chat history and transcription store
user_memory = {}
user_transcriptions = {} # Format: {user_id: {message_id: "transcription_text"}}

# Statistics counters (global variables)
total_files_processed = 0
total_audio_files = 0
total_voice_clips = 0
total_videos = 0
total_processing_time = 0  # in seconds
processing_start_time = None

GEMINI_API_KEY = "AIzaSyAto78yGVZobxOwPXnl8wCE9ZW8Do2R8HA" # Replace with your actual Gemini API key

def ask_gemini(user_id, user_message):
    user_memory.setdefault(user_id, []).append({"role": "user", "text": user_message})
    # Keep only the last 10 messages for context to avoid hitting token limits
    history = user_memory[user_id][-10:]
    parts = [{"text": msg["text"]} for msg in history]
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"
    try:
        resp = requests.post(url, headers={'Content-Type': 'application/json'}, json={"contents": [{"parts": parts}]})
        resp.raise_for_status() # Raise an exception for HTTP errors
        result = resp.json()
        if "candidates" in result:
            reply = result['candidates'][0]['content']['parts'][0]['text']
            user_memory[user_id].append({"role": "model", "text": reply})
            return reply
        return "Error: " + json.dumps(result)
    except requests.exceptions.RequestException as e:
        logging.error(f"Gemini API request failed: {e}")
        return f"Error: Failed to connect to Gemini API. {e}"
    except json.JSONDecodeError:
        logging.error(f"Gemini API returned invalid JSON: {resp.text}")
        return "Error: Invalid response from Gemini API."

FILE_SIZE_LIMIT = 20 * 1024 * 1024  # 20MB
admin_state = {}

def set_bot_info():
    commands = [
        telebot.types.BotCommand("start", "Restart the bot"),
        telebot.types.BotCommand("status", "View Bot statistics"),
        telebot.types.BotCommand("help", "View instructions"),
        telebot.types.BotCommand("language", "Change preferred language for translate/summarize"),
        telebot.types.BotCommand("privacy", "View privacy notice"),
    ]
    bot.set_my_commands(commands)

    # Short description (About)
    bot.set_my_short_description(
        "Got media files? Let this free bot transcribe, summarize, and translate them in seconds!"
    )

    # Full description (What can this bot do?)
    bot.set_my_description(
        """This bot quickly transcribes, summarizes, and translates voice messages, audio files, and videos‚Äîfree and in multiple languages.

     üî•Enjoy free usage and start now!üëåüèª"""
    )

def update_user_activity(user_id):
    user_data[str(user_id)] = datetime.now().isoformat()
    save_user_data()

@bot.message_handler(commands=['start'])
def start_handler(message):
    user_id = str(message.from_user.id)
    update_user_activity(message.from_user.id)
    if user_id not in user_data:
        user_data[user_id] = datetime.now().isoformat()
        save_user_data()
    if message.from_user.id == ADMIN_ID:
        keyboard = telebot.types.ReplyKeyboardMarkup(resize_keyboard=True)
        keyboard.add("Send Broadcast", "Total Users", "/status")
        bot.send_message(message.chat.id, "Admin Panel", reply_markup=keyboard)
    else:
        name = f"@{message.from_user.username}" if message.from_user.username else message.from_user.first_name
        bot.send_message(
            message.chat.id,
            f"""üëãüèª Welcome dear!
‚Ä¢ Send me:
‚Ä¢ Voice message
‚Ä¢ Video message
‚Ä¢ Audio file
‚Ä¢ to transcribe for free"""
        )

@bot.message_handler(commands=['help'])
def help_handler(message):
    help_text = (
        """‚ÑπÔ∏è How to use this bot:

This bot transcribes voice messages, audio files, and videos.

1.  **Send a File:** Send a voice message, audio, or video.
2.  **Receive Transcription:** The bot will process your input and send back the transcribed text. Long transcriptions will be sent as a text file.
3.  **Post-Transcription Actions:** After transcription, you'll see options to **Translate** or **Summarize** the text.
4.  **Commands:**
    -   `/start`: Restart the bot.
    -   `/status`: View bot statistics.
    -   `/help`: Display these instructions.
    -   `/language`: Change your preferred language for translations and summaries.
    -   `/privacy`: View the bot's privacy notice.

Enjoy transcribing your media quickly and easily!"""
    )
    bot.send_message(message.chat.id, help_text, parse_mode="Markdown")

@bot.message_handler(commands=['privacy'])
def privacy_notice_handler(message):
    privacy_text = (
        """**Privacy Notice**

Your privacy is important to us. Here's how this bot handles your data:

1.  **Data We Process:**
    * **Media Files:** Voice messages, audio files, video files, and TikTok links you send are temporarily processed for transcription. These files are **deleted immediately** after processing. We do not store your media content.
    * **Transcriptions:** The text transcriptions generated from your media are stored temporarily in memory for subsequent actions (like translation or summarization) for a limited time (e.g., until a new transcription is made or the bot is restarted). We do not permanently store your transcription data on our servers.
    * **User IDs:** Your Telegram User ID is stored to manage your language preferences and track basic activity (like last seen) to improve bot service and provide aggregated usage statistics. This ID is not linked to any personal identifying information outside of Telegram.
    * **Language Preferences:** Your chosen language for translations and summaries is stored so you don't have to select it each time.

2.  **How We Use Your Data:**
    * To provide the core functionality of the bot: transcription, translation, and summarization.
    * To improve bot performance and understand usage patterns through anonymous, aggregated statistics (e.g., total files processed).
    * To set your preferred language for future interactions.

3.  **Data Sharing:**
    * We **do not share** your personal data, media files, or transcriptions with any third parties.
    * Transcription, translation, and summarization are performed using integrated AI models (Whisper and Gemini API). Your text input to these models is handled according to their respective privacy policies, but we do not store this data after processing.

4.  **Data Retention:**
    * Media files are deleted immediately after transcription.
    * Transcriptions are held temporarily in memory.
    * User IDs and language preferences are retained to maintain your settings and usage statistics. You can always delete your data by stopping using the bot or contacting the bot administrator.

By using this bot, you agree to the terms outlined in this Privacy Notice.

If you have any questions, please contact the bot administrator."""
    )
    bot.send_message(message.chat.id, privacy_text, parse_mode="Markdown")

@bot.message_handler(commands=['status'])
def status_handler(message):
    update_user_activity(message.from_user.id)

    # Count active users today
    today = datetime.now().date()
    active_today = sum(
        1 for timestamp in user_data.values()
        if datetime.fromisoformat(timestamp).date() == today
    )

    # Calculate time components
    total_seconds = int(total_processing_time)
    hours = total_seconds // 3600
    minutes = (total_seconds % 3600) // 60
    seconds = total_seconds % 60

    text = (
        "üìä Overall Statistics\n\n"
        "üë• User Statistics\n"
        f"‚ñ´Ô∏è Total Users Today: {active_today}\n\n"
        "‚öôÔ∏è Processing Statistics\n"
        f"‚ñ´Ô∏è Total Files Processed: {total_files_processed}\n"
        f"‚ñ´Ô∏è Audio Files: {total_audio_files}\n"
        f"‚ñ´Ô∏è Voice Clips: {total_voice_clips}\n"
        f"‚ñ´Ô∏è Videos: {total_videos}\n"
        f"‚è±Ô∏è Total Processing Time: {hours} hours {minutes} minutes {seconds} seconds\n\n"
        "‚∏ª\n\n"
        "Thanks for using our service! üôå\n"
        "See you next time! üí´"
    )

    bot.send_message(message.chat.id, text)

@bot.message_handler(func=lambda m: m.text == "Total Users" and m.from_user.id == ADMIN_ID)
def total_users(message):
    bot.send_message(message.chat.id, f"Total registered users: {len(user_data)}")

@bot.message_handler(func=lambda m: m.text == "Send Broadcast" and m.from_user.id == ADMIN_ID)
def send_broadcast(message):
    admin_state[message.from_user.id] = 'awaiting_broadcast'
    bot.send_message(message.chat.id, "Send the broadcast message now:")

@bot.message_handler(
    func=lambda m: m.from_user.id == ADMIN_ID and admin_state.get(m.from_user.id) == 'awaiting_broadcast',
    content_types=['text', 'photo', 'video', 'audio', 'document']
)
def broadcast_message(message):
    admin_state[message.from_user.id] = None
    success = fail = 0
    for uid in user_data:
        try:
            bot.copy_message(uid, message.chat.id, message.message_id)
            success += 1
        except telebot.apihelper.ApiTelegramException:
            fail += 1
    bot.send_message(
        message.chat.id,
        f"Broadcast complete.\nSuccessful: {success}\nFailed: {fail}"
    )

@bot.message_handler(content_types=['voice', 'audio', 'video', 'video_note'])
def handle_file(message):
    global total_files_processed, total_audio_files, total_voice_clips, total_videos, total_processing_time
    update_user_activity(message.from_user.id)

    # Add reaction emoji based on file type
    try:
        if message.voice:
            bot.set_message_reaction(chat_id=message.chat.id, message_id=message.message_id, reaction=["üëÄ"])
        elif message.audio:
            bot.set_message_reaction(chat_id=message.chat.id, message_id=message.message_id, reaction=["üëÄ"])
        elif message.video or message.video_note:
            bot.set_message_reaction(chat_id=message.chat.id, message_id=message.message_id, reaction=["üëÄ"])
    except Exception as e:
        logging.error(f"Error setting reaction: {e}")

    file_obj = message.voice or message.audio or message.video or message.video_note
    if file_obj.file_size > FILE_SIZE_LIMIT:
        return bot.send_message(message.chat.id, "The file size you uploaded is too large (max allowed is 20MB).")

    info = bot.get_file(file_obj.file_id)
    # Use a unique temporary path for the downloaded file, ensuring it's always .ogg first
    downloaded_file_path = os.path.join(DOWNLOAD_DIR, f"{uuid.uuid4()}.ogg")
    
    bot.send_chat_action(message.chat.id, 'typing')

    try:
        data = bot.download_file(info.file_path)
        with open(downloaded_file_path, 'wb') as f:
            f.write(data)

        bot.send_chat_action(message.chat.id, 'typing')
        global processing_start_time
        processing_start_time = datetime.now()

        # Call the updated transcribe function that handles chunking
        transcription = transcribe_large_audio(downloaded_file_path) or ""
        uid = str(message.from_user.id)

        user_transcriptions.setdefault(uid, {})[message.message_id] = transcription

        total_files_processed += 1
        if message.voice:
            total_voice_clips += 1
        elif message.audio:
            total_audio_files += 1
        elif message.video or message.video_note:
            total_videos += 1

        processing_time = (datetime.now() - processing_start_time).total_seconds()
        total_processing_time += processing_time

        buttons = InlineKeyboardMarkup()
        buttons.add(
            InlineKeyboardButton("Translate ", callback_data=f"btn_translate|{message.message_id}"),
            InlineKeyboardButton("Summarize ", callback_data=f"btn_summarize|{message.message_id}")
        )

        if len(transcription) > 4000:
            fn = os.path.join(DOWNLOAD_DIR, f'transcription_{uuid.uuid4()}.txt') # Unique filename
            with open(fn, 'w', encoding='utf-8') as f:
                f.write(transcription)
            bot.send_chat_action(message.chat.id, 'upload_document')
            with open(fn, 'rb') as doc:
                bot.send_document(
                    message.chat.id,
                    doc,
                    reply_to_message_id=message.message_id,
                    reply_markup=buttons,
                    caption="Here‚Äôs your transcription. Tap a button below to translate or summarize."
                )
            os.remove(fn)
        else:
            bot.reply_to(
                message,
                transcription,
                reply_markup=buttons
            )
    except Exception as e:
        logging.error(f"Error processing file: {e}")
        bot.send_message(message.chat.id, "‚ö†Ô∏è An error occurred during transcription.")
    finally:
        # Clean up the downloaded file
        if os.path.exists(downloaded_file_path):
            os.remove(downloaded_file_path)
        # Ensure any chunk files are also cleaned up if created
        for f in os.listdir(DOWNLOAD_DIR):
            if f.startswith("chunk_") and f.endswith(".ogg"):
                os.remove(os.path.join(DOWNLOAD_DIR, f))


# --- Language Selection and Saving ---

# List of common languages with emojis (ordered by approximate global prevalence/popularity)
LANGUAGES = [
    {"name": "English", "flag": "üá¨üáß"},
    {"name": "Chinese", "flag": "üá®üá≥"},
    {"name": "Spanish", "flag": "üá™üá∏"},
    {"name": "Hindi", "flag": "üáÆüá≥"},
    {"name": "Arabic", "flag": "üá∏üá¶"},
    {"name": "French", "flag": "üá´üá∑"},
    {"name": "Bengali", "flag": "üáßüá©"},
    {"name": "Russian", "flag": "üá∑üá∫"},
    {"name": "Portuguese", "flag": "üáµüáπ"},
    {"name": "Urdu", "flag": "üáµüá∞"},
    {"name": "German", "flag": "üá©üá™"},
    {"name": "Japanese", "flag": "üáØüáµ"},
    {"name": "Korean", "flag": "üá∞üá∑"},
    {"name": "Vietnamese", "flag": "üáªüá≥"},
    {"name": "Turkish", "flag": "üáπüá∑"},
    {"name": "Italian", "flag": "üáÆüáπ"},
    {"name": "Thai", "flag": "üáπüá≠"},
    {"name": "Swahili", "flag": "üá∞üá™"},
    {"name": "Dutch", "flag": "üá≥üá±"},
    {"name": "Polish", "flag": "üáµüá±"},
    {"name": "Ukrainian", "flag": "üá∫üá¶"},
    {"name": "Indonesian", "flag": "üáÆüá©"},
    {"name": "Malay", "flag": "üá≤üáæ"},
    {"name": "Filipino", "flag": "üáµüá≠"},
    {"name": "Persian", "flag": "üáÆüá∑"},
    {"name": "Amharic", "flag": "üá™üáπ"},
    {"name": "Somali", "flag": "üá∏üá¥"},
    {"name": "Swedish", "flag": "üá∏üá™"},
    {"name": "Norwegian", "flag": "üá≥üá¥"},
    {"name": "Danish", "flag": "üá©üá∞"},
    {"name": "Finnish", "flag": "üá´üáÆ"},
    {"name": "Greek", "flag": "üá¨üá∑"},
    {"name": "Hebrew", "flag": "üáÆüá±"},
    {"name": "Czech", "flag": "üá®üáø"},
    {"name": "Hungarian", "flag": "üá≠üá∫"},
    {"name": "Romanian", "flag": "üá∑üá¥"},
    {"name": "Nepali", "flag": "üá≥üáµ"},
    {"name": "Sinhala", "flag": "üá±üá∞"},
    {"name": "Tamil", "flag": "üáÆüá≥"},
    {"name": "Telugu", "flag": "üáÆüá≥"},
    {"name": "Kannada", "flag": "üáÆüá≥"},
    {"name": "Malayalam", "flag": "üáÆüá≥"},
    {"name": "Gujarati", "flag": "üáÆüá≥"},
    {"name": "Punjabi", "flag": "üáÆüá≥"},
    {"name": "Marathi", "flag": "üáÆüá≥"},
    {"name": "Oriya", "flag": "üáÆüá≥"},
    {"name": "Assamese", "flag": "üáÆüá≥"},
    {"name": "Khmer", "flag": "üá∞üá≠"},
    {"name": "Lao", "flag": "üá±üá¶"},
    {"name": "Burmese", "flag": "üá≤üá≤"},
    {"name": "Georgian", "flag": "üá¨üá™"},
    {"name": "Armenian", "flag": "üá¶üá≤"},
    {"name": "Azerbaijani", "flag": "üá¶üáø"},
    {"name": "Kazakh", "flag": "üá∞üáø"},
    {"name": "Uzbek", "flag": "üá∫üáø"},
    {"name": "Kyrgyz", "flag": "üá∞üá¨"},
    {"name": "Tajik", "flag": "üáπüáØ"},
    {"name": "Turkmen", "flag": "üáπüá≤"},
    {"name": "Mongolian", "flag": "üá≤üá≥"},
    {"name": "Estonian", "flag": "üá™üá™"},
    {"name": "Latvian", "flag": "üá±üáª"},
    {"name": "Lithuanian", "flag": "üá±üáπ"},
]


def generate_language_keyboard(callback_prefix, message_id=None):
    markup = InlineKeyboardMarkup(row_width=3)
    buttons = []
    for lang in LANGUAGES:
        cb_data = f"{callback_prefix}|{lang['name']}"
        if message_id is not None:
            cb_data += f"|{message_id}"
        buttons.append(InlineKeyboardButton(f"{lang['name']} {lang['flag']}", callback_data=cb_data))
    markup.add(*buttons)
    return markup

@bot.message_handler(commands=['language'])
def select_language_command(message):
    uid = str(message.from_user.id)
    markup = generate_language_keyboard("set_lang")
    bot.send_message(
        message.chat.id,
        "Please select your preferred language for future translations and summaries:",
        reply_markup=markup
    )

@bot.callback_query_handler(func=lambda c: c.data.startswith("set_lang|"))
def callback_set_language(call):
    uid = str(call.from_user.id)
    _, lang = call.data.split("|", 1)
    user_language_settings[uid] = lang
    save_user_language_settings()
    bot.edit_message_text(
        chat_id=call.message.chat.id,
        message_id=call.message.message_id,
        text=f"‚úÖ Your preferred language has been set to: **{lang}**",
        parse_mode="Markdown"
    )
    bot.answer_callback_query(call.id, text=f"Language set to {lang}")

@bot.callback_query_handler(func=lambda c: c.data.startswith("btn_translate|"))
def button_translate_handler(call):
    uid = str(call.from_user.id)
    _, message_id_str = call.data.split("|", 1)
    message_id = int(message_id_str)

    if uid not in user_transcriptions or message_id not in user_transcriptions[uid]:
        bot.answer_callback_query(call.id, "‚ùå No transcription found for this message.")
        return

    preferred_lang = user_language_settings.get(uid)
    if preferred_lang:
        bot.answer_callback_query(call.id, f"Translating to {preferred_lang}...", show_alert=False)
        do_translate_with_saved_lang(call.message, uid, preferred_lang, message_id)
    else:
        markup = generate_language_keyboard("translate_to", message_id)
        bot.edit_message_text(
            chat_id=call.message.chat.id,
            message_id=call.message.message_id,
            text="Please select the language you want to translate into:",
            reply_markup=markup
        )
    bot.answer_callback_query(call.id) # Answer the callback immediately to remove loading state

@bot.callback_query_handler(func=lambda c: c.data.startswith("btn_summarize|"))
def button_summarize_handler(call):
    uid = str(call.from_user.id)
    _, message_id_str = call.data.split("|", 1)
    message_id = int(message_id_str)

    if uid not in user_transcriptions or message_id not in user_transcriptions[uid]:
        bot.answer_callback_query(call.id, "‚ùå No transcription found for this message.")
        return

    preferred_lang = user_language_settings.get(uid)
    if preferred_lang:
        bot.answer_callback_query(call.id, f"Summarizing in {preferred_lang}...", show_alert=False)
        do_summarize_with_saved_lang(call.message, uid, preferred_lang, message_id)
    else:
        markup = generate_language_keyboard("summarize_in", message_id)
        bot.edit_message_text(
            chat_id=call.message.chat.id,
            message_id=call.message.message_id,
            text="Please select the language you want the summary in:",
            reply_markup=markup
        )
    bot.answer_callback_query(call.id) # Answer the callback immediately to remove loading state

@bot.callback_query_handler(func=lambda c: c.data.startswith("translate_to|"))
def callback_translate_to(call):
    uid = str(call.from_user.id)
    parts = call.data.split("|")
    lang = parts[1]
    message_id = int(parts[2]) if len(parts) > 2 else None

    user_language_settings[uid] = lang
    save_user_language_settings()
    bot.edit_message_text(
        chat_id=call.message.chat.id,
        message_id=call.message.message_id,
        text=f"Translating to **{lang}**...",
        parse_mode="Markdown"
    )
    if message_id:
        do_translate_with_saved_lang(call.message, uid, lang, message_id)
    else:
        # Fallback if message_id is not in callback data (e.g., old callbacks, direct /translate command)
        if uid in user_transcriptions and call.message.reply_to_message and call.message.reply_to_message.message_id in user_transcriptions[uid]:
             do_translate_with_saved_lang(call.message, uid, lang, call.message.reply_to_message.message_id)
        else:
            bot.send_message(call.message.chat.id, "‚ùå No transcription found for this message to translate. Please use the inline buttons on the transcription.")
    bot.answer_callback_query(call.id)

@bot.callback_query_handler(func=lambda c: c.data.startswith("summarize_in|"))
def callback_summarize_in(call):
    uid = str(call.from_user.id)
    parts = call.data.split("|")
    lang = parts[1]
    message_id = int(parts[2]) if len(parts) > 2 else None

    user_language_settings[uid] = lang
    save_user_language_settings()
    bot.edit_message_text(
        chat_id=call.message.chat.id,
        message_id=call.message.message_id,
        text=f"Summarizing in **{lang}**...",
        parse_mode="Markdown"
    )
    if message_id:
        do_summarize_with_saved_lang(call.message, uid, lang, message_id)
    else:
        # Fallback if message_id is not in callback data
        if uid in user_transcriptions and call.message.reply_to_message and call.message.reply_to_message.message_id in user_transcriptions[uid]:
            do_summarize_with_saved_lang(call.message, uid, lang, call.message.reply_to_message.message_id)
        else:
            bot.send_message(call.message.chat.id, "‚ùå No transcription found for this message to summarize. Please use the inline buttons on the transcription.")
    bot.answer_callback_query(call.id)

def do_translate_with_saved_lang(message, uid, lang, message_id):
    original = user_transcriptions.get(uid, {}).get(message_id, "")
    if not original:
        bot.send_message(message.chat.id, "‚ùå No transcription available for this specific message to translate.")
        return

    prompt = f"Translate the following text into {lang}. Provide only the translated text, with no additional notes, explanations, or introductory/concluding remarks:\n\n{original}"

    bot.send_chat_action(message.chat.id, 'typing')
    translated = ask_gemini(uid, prompt)

    if translated.startswith("Error:"):
        bot.send_message(message.chat.id, f"Error during translation: {translated}")
        return

    if len(translated) > 4000:
        fn = os.path.join(DOWNLOAD_DIR, f'translation_{uuid.uuid4()}.txt') # Unique filename
        with open(fn, 'w', encoding='utf-8') as f:
            f.write(translated)
        bot.send_chat_action(message.chat.id, 'upload_document')
        with open(fn, 'rb') as doc:
            bot.send_document(message.chat.id, doc, caption=f"Translation to {lang}", reply_to_message_id=message_id)
        os.remove(fn)
    else:
        bot.send_message(message.chat.id, translated, reply_to_message_id=message_id)

def do_summarize_with_saved_lang(message, uid, lang, message_id):
    original = user_transcriptions.get(uid, {}).get(message_id, "")
    if not original:
        bot.send_message(message.chat.id, "‚ùå No transcription available for this specific message to summarize.")
        return

    prompt = f"Summarize the following text in {lang}. Provide only the summarized text, with no additional notes, explanations, or different versions:\n\n{original}"

    bot.send_chat_action(message.chat.id, 'typing')
    summary = ask_gemini(uid, prompt)

    if summary.startswith("Error:"):
        bot.send_message(message.chat.id, f"Error during summarization: {summary}")
        return

    if len(summary) > 4000:
        fn = os.path.join(DOWNLOAD_DIR, f'summary_{uuid.uuid4()}.txt') # Unique filename
        with open(fn, 'w', encoding='utf-8') as f:
            f.write(summary)
        bot.send_chat_action(message.chat.id, 'upload_document')
        with open(fn, 'rb') as doc:
            bot.send_document(message.chat.id, doc, caption=f"Summary in {lang}", reply_to_message_id=message_id)
        os.remove(fn)
    else:
        bot.send_message(message.chat.id, summary, reply_to_message_id=message_id)

# --- Function to handle audio chunking and transcription ---
def transcribe_large_audio(audio_path: str) -> str | None:
    try:
        # Load the audio file
        audio = AudioSegment.from_file(audio_path)
        total_length_ms = len(audio) # Length in milliseconds

        # Define chunk size and overlap
        # Convert seconds to milliseconds
        CHUNK_LENGTH_MS = 10 * 1000 # 10 seconds
        OVERLAP_LENGTH_MS = 1 * 1000 # 1 second overlap

        all_transcriptions = []
        start_ms = 0

        while start_ms < total_length_ms:
            end_ms = start_ms + CHUNK_LENGTH_MS
            # Adjust end_ms to not exceed total_length
            if end_ms > total_length_ms:
                end_ms = total_length_ms

            chunk = audio[start_ms:end_ms]
            chunk_file_path = os.path.join(DOWNLOAD_DIR, f"chunk_{uuid.uuid4()}.ogg")
            chunk.export(chunk_file_path, format="ogg")

            logging.info(f"Transcribing chunk from {start_ms/1000:.2f}s to {end_ms/1000:.2f}s")
            # Using model.transcribe for the actual speech recognition
            segments, _ = model.transcribe(chunk_file_path, beam_size=1)
            chunk_transcription = " ".join(segment.text for segment in segments)
            all_transcriptions.append(chunk_transcription)

            # Clean up chunk file
            os.remove(chunk_file_path)

            # Move to the next chunk with overlap
            # Ensure we don't move backwards if overlap is too large relative to chunk size
            start_ms += (CHUNK_LENGTH_MS - OVERLAP_LENGTH_MS)
            if start_ms >= total_length_ms: # Ensure we don't go past the end if the last chunk was too short
                break

        return " ".join(all_transcriptions)
    except Exception as e:
        logging.error(f"Error during audio chunking or transcription: {e}")
        return None


@bot.message_handler(commands=['translate'])
def handle_translate(message):
    uid = str(message.from_user.id)
    if not message.reply_to_message or uid not in user_transcriptions or message.reply_to_message.message_id not in user_transcriptions[uid]:
        return bot.send_message(message.chat.id, "‚ùå Please reply to a transcription message to translate it.")

    transcription_message_id = message.reply_to_message.message_id
    preferred_lang = user_language_settings.get(uid)
    if preferred_lang:
        do_translate_with_saved_lang(message, uid, preferred_lang, transcription_message_id)
    else:
        markup = generate_language_keyboard("translate_to", transcription_message_id)
        bot.send_message(
            message.chat.id,
            "Please select the language you want to translate into:",
            reply_markup=markup
        )

@bot.message_handler(commands=['summarize'])
def handle_summarize(message):
    uid = str(message.from_user.id)
    if not message.reply_to_message or uid not in user_transcriptions or message.reply_to_message.message_id not in user_transcriptions[uid]:
        return bot.send_message(message.chat.id, "‚ùå Please reply to a transcription message to summarize it.")

    transcription_message_id = message.reply_to_message.message_id
    preferred_lang = user_language_settings.get(uid)
    if preferred_lang:
        do_summarize_with_saved_lang(message, uid, preferred_lang, transcription_message_id)
    else:
        markup = generate_language_keyboard("summarize_in", transcription_message_id)
        bot.send_message(
            message.chat.id,
            "Please select the language you want the summary in:",
            reply_markup=markup
        )

@bot.message_handler(func=lambda m: True, content_types=['text', 'photo', 'sticker', 'document'])
def fallback(message):
    update_user_activity(message.from_user.id)
    bot.send_message(message.chat.id, "Please send only voice, audio, or video files.")

@app.route('/', methods=['POST'])
def webhook():
    if request.headers.get('content-type') == 'application/json':
        update = telebot.types.Update.de_json(request.get_data().decode('utf-8'))
        bot.process_new_updates([update])
        return '', 200
    return abort(403)

@app.route('/set_webhook', methods=['GET','POST'])
def set_webhook():
    url = "https://only-me-cwkd.onrender.com" # Replace with your actual Render URL
    bot.set_webhook(url=url)
    return f"Webhook set to {url}", 200

@app.route('/delete_webhook', methods=['GET','POST'])
def delete_webhook():
    bot.delete_webhook()
    return 'Webhook deleted.', 200

if __name__ == "__main__":
    # Clean up download directory before starting
    if os.path.exists(DOWNLOAD_DIR):
        shutil.rmtree(DOWNLOAD_DIR)
    os.makedirs(DOWNLOAD_DIR, exist_ok=True)
    
    set_bot_info()
    # It's good practice to delete existing webhook before setting a new one
    bot.delete_webhook() 
    # Replace "https://media-transcriber-bot-hzlk.onrender.com" with your actual Render deploy URL
    bot.set_webhook(url="https://media-transcriber-bot.onrender.com") 
    app.run(host="0.0.0.0", port=int(os.environ.get('PORT', 8080)))
